# ğŸ“ˆ Real-Time BTC/USDT Market Analytics Platform

A **real-time streaming analytics system** that ingests live cryptocurrency market data, processes it using **Kafka**, aggregates it into **OHLCV candles**, and visualizes it in a **live interactive dashboard using Streamlit**.

This project demonstrates **end-to-end real-time data engineering**, similar to systems used in **trading platforms, fintech analytics, and market surveillance tools**.

---

## ğŸš€ Features

- ğŸ”´ Live BTC/USDT data ingestion from Binance WebSocket
- âš¡ Real-time streaming pipeline using Apache Kafka
- ğŸ“Š OHLCV (Open, High, Low, Close, Volume) aggregation
- ğŸ•’ Time-windowed candle generation (1-minute)
- ğŸ“ˆ Live candlestick dashboard (auto-updating)
- ğŸ§  Streaming-friendly architecture (no polling DB hacks)

---

## ğŸ—ï¸ System Architecture

```

Binance WebSocket
â”‚
â–¼
Kafka Producer (raw_ticks)
â”‚
â–¼
Kafka Topic: raw_ticks
â”‚
â–¼
OHLCV Aggregator (Kafka Consumer + Producer)
â”‚
â–¼
Kafka Topic: ohlcv_1m
â”‚
â–¼
Streamlit Dashboard (Kafka Consumer)

```

---

## ğŸ§° Tech Stack

| Layer              | Technology |
|-------------------|------------|
| Data Source       | Binance WebSocket API |
| Streaming Broker  | Apache Kafka |
| Processing        | Python |
| Messaging Client  | confluent-kafka |
| Visualization     | Streamlit + Plotly |
| Containerization  | Docker + Docker Compose |

---

## ğŸ“ Project Structure

```

project-realtime/
â”‚
â”œâ”€â”€ docker-compose.yml        # Kafka + Zookeeper setup
â”œâ”€â”€ producer_ws_to_kafka.py   # WebSocket â†’ Kafka (raw ticks)
â”œâ”€â”€ ohlcv_aggregator.py       # raw_ticks â†’ ohlcv_1m
â”œâ”€â”€ dashboard.py              # Streamlit real-time dashboard
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âœ… Prerequisites

Make sure you have the following installed:

- **Python 3.11.x**
- **Docker Desktop** (with WSL2 enabled on Windows)
- **pip**
- Internet connection

Verify:
```bash
python --version
docker --version
````

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### `requirements.txt`

```
streamlit
pandas
plotly
confluent-kafka==2.3.0
websockets
```

Verify Kafka client:

```bash
python -c "from confluent_kafka import Consumer; print('Kafka OK')"
```

---

## ğŸ³ Running Kafka (Docker)

From the project root:

```bash
docker compose up -d
```

Confirm:

```bash
docker ps
```

You should see:

* `cp-kafka`
* `cp-zookeeper`

---

## â–¶ï¸ Running the Application

### Step 1: Start Binance WebSocket Producer

Streams live BTC/USDT trades into Kafka.

```bash
python producer_ws_to_kafka.py
```

Expected output:

```
Sent tick â†’ BTCUSDT 90241.12
Sent tick â†’ BTCUSDT 90241.35
```

---

### Step 2: Start OHLCV Aggregator

Consumes raw ticks and generates 1-minute OHLCV candles.

```bash
python ohlcv_aggregator.py
```

Expected output:

```
OHLCV: {'time': 173..., 'open': ..., 'high': ..., 'low': ..., 'close': ..., 'volume': ...}
```

---

### Step 3: Start Streamlit Dashboard

Open a **new terminal**:

```bash
python -m streamlit run dashboard.py
```

Open in browser:

```
http://localhost:8501
```

---

## ğŸ“Š Dashboard Output

* Live **candlestick chart**
* Auto-refresh every second
* Candles update as soon as Kafka publishes data
* No database polling
* True streaming behavior

â³ First candle appears after ~1 minute.

---

## â— Common Issues & Fixes

### Kafka not running

```bash
docker compose down
docker compose up -d
```

### `No module named confluent_kafka`

```bash
pip install confluent-kafka==2.3.0
```

### Dashboard stuck on â€œWaiting for OHLCV dataâ€

âœ” Ensure both scripts are running:

* `producer_ws_to_kafka.py`
* `ohlcv_aggregator.py`

---

## ğŸ§  Why This Project Matters

This project demonstrates:

* Real-time data ingestion (not batch)
* Event-driven architecture
* Streaming analytics with Kafka
* Time-window aggregation
* Live dashboards without REST polling

These patterns are used in:

* Trading platforms
* Fraud detection systems
* Market surveillance
* IoT streaming analytics
* Financial data engineering roles

---

## ğŸ”® Future Enhancements

* RSI / MACD indicators
* Alert system (Overbought / Oversold)
* Store data in TimescaleDB
* LSTM-based trend prediction
* Multi-symbol support
* Cloud deployment (Kafka + UI split)

---

